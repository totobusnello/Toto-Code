#!/usr/bin/env python3
"""
Hybrid Memory Architecture Demonstration

This script demonstrates the key features of the SAFLA Hybrid Memory Architecture
implemented using Test-Driven Development methodology.
"""

import asyncio
import numpy as np
from datetime import datetime, timedelta
from typing import List

# Add the parent directory to the path to import our modules
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# Import our hybrid memory components
from safla.core.hybrid_memory import (
    HybridMemoryArchitecture,
    EpisodicEvent,
    WorkingMemoryContext,
    SemanticNode,
    SimilarityMetric
)
from safla.core.memory_optimizations import (
    create_optimized_memory_manager,
    MemoryPerformanceMonitor
)


async def demonstrate_hybrid_memory():
    """Demonstrate the Hybrid Memory Architecture capabilities."""
    
    print("ğŸ§  SAFLA Hybrid Memory Architecture Demonstration")
    print("=" * 60)
    
    # Initialize hybrid memory with optimized configuration
    print("\n1. Initializing Hybrid Memory Architecture...")
    
    vector_config = {
        'embedding_dim': 512,
        'similarity_metric': SimilarityMetric.COSINE,
        'max_capacity': 1000
    }
    
    hybrid_memory = HybridMemoryArchitecture(vector_config=vector_config)
    performance_monitor = MemoryPerformanceMonitor()
    
    print(f"âœ… Initialized with {hybrid_memory.vector_memory.embedding_dim}D vectors")
    print(f"âœ… Vector capacity: {hybrid_memory.vector_memory.max_capacity}")
    print(f"âœ… Similarity metric: {hybrid_memory.vector_memory.similarity_metric.value}")
    
    # Demonstrate vector memory operations
    print("\n2. Vector Memory Operations...")
    
    # Store some sample vectors
    sample_embeddings = [
        np.random.rand(512).astype(np.float32) for _ in range(5)
    ]
    sample_metadata = [
        {"type": "concept", "name": f"concept_{i}", "importance": 0.8 + i * 0.05}
        for i in range(5)
    ]
    
    vector_ids = []
    for i, (embedding, metadata) in enumerate(zip(sample_embeddings, sample_metadata)):
        start_time = datetime.now()
        vector_id = hybrid_memory.vector_memory.store(embedding, metadata)
        end_time = datetime.now()
        
        duration_ms = (end_time - start_time).total_seconds() * 1000
        performance_monitor.record_operation_time('store', duration_ms)
        vector_ids.append(vector_id)
        
        print(f"  ğŸ“¦ Stored vector {i+1}: {vector_id[:8]}... ({metadata['name']})")
    
    # Perform similarity search
    print("\n3. Similarity Search...")
    
    query_vector = sample_embeddings[0]  # Use first vector as query
    start_time = datetime.now()
    results = hybrid_memory.vector_memory.similarity_search(query_vector, k=3)
    end_time = datetime.now()
    
    duration_ms = (end_time - start_time).total_seconds() * 1000
    performance_monitor.record_operation_time('search', duration_ms)
    
    print(f"  ğŸ” Found {len(results)} similar vectors:")
    for i, result in enumerate(results):
        metadata = result.item.metadata
        print(f"    {i+1}. {metadata['name']} (similarity: {result.similarity_score:.3f})")
    
    # Demonstrate episodic memory
    print("\n4. Episodic Memory Operations...")
    
    # Create sample episodic events
    base_time = datetime.now()
    events = []
    
    for i in range(3):
        event = EpisodicEvent(
            event_id=f"event_{i}",
            timestamp=base_time - timedelta(minutes=i * 10),
            event_type="user_interaction" if i % 2 == 0 else "system_event",
            context={"action": f"action_{i}", "user_id": f"user_{i % 2}"},
            embedding=np.random.rand(512).astype(np.float32)
        )
        hybrid_memory.episodic_memory.store_event(event)
        events.append(event)
        print(f"  ğŸ“… Stored event: {event.event_id} ({event.event_type})")
    
    # Retrieve recent events
    recent_events = hybrid_memory.episodic_memory.retrieve_recent(count=2)
    print(f"  ğŸ“‹ Retrieved {len(recent_events)} recent events")
    
    # Demonstrate semantic memory
    print("\n5. Semantic Memory Operations...")
    
    # Add semantic concepts
    concepts = ["learning", "memory", "intelligence", "reasoning", "knowledge"]
    concept_embeddings = {
        concept: np.random.rand(512).astype(np.float32) 
        for concept in concepts
    }
    
    for i, (concept, embedding) in enumerate(concept_embeddings.items()):
        node = SemanticNode(
            node_id=f"concept_{i}",
            concept=concept,
            attributes={"type": "concept"},
            embedding=embedding
        )
        hybrid_memory.semantic_memory.add_node(node)
        print(f"  ğŸ§© Added concept: {concept}")
    
    # Add relationships
    relationships = [
        ("concept_0", "concept_1", "relates_to", 0.8),  # learning -> memory
        ("concept_1", "concept_2", "enables", 0.7),     # memory -> intelligence
        ("concept_2", "concept_3", "supports", 0.9),    # intelligence -> reasoning
        ("concept_3", "concept_4", "creates", 0.6)      # reasoning -> knowledge
    ]
    
    for source_id, target_id, rel_type, weight in relationships:
        hybrid_memory.semantic_memory.add_relationship(source_id, target_id, rel_type, weight)
        print(f"  ğŸ”— Added relationship: {source_id} â†’ {target_id} ({rel_type}, weight: {weight})")
    
    # Find shortest path
    path = hybrid_memory.semantic_memory.find_shortest_path("concept_0", "concept_4")
    if path:
        print(f"  ğŸ›¤ï¸  Shortest path from 'learning' to 'knowledge': {' â†’ '.join(path)}")
    
    # Demonstrate working memory
    print("\n6. Working Memory Operations...")
    
    # Add contexts to working memory
    contexts = []
    for i in range(3):
        context = WorkingMemoryContext(
            context_id=f"context_{i}",
            content=f"Active task {i}: processing user request",
            attention_weight=0.7 + i * 0.1,
            timestamp=datetime.now(),
            embedding=np.random.rand(512).astype(np.float32)
        )
        hybrid_memory.working_memory.add_context(context)
        contexts.append(context)
        print(f"  ğŸ¯ Added context: {context.context_id} (attention: {context.attention_weight:.2f})")
    
    # Get active contexts
    active_contexts = hybrid_memory.working_memory.get_active_contexts()
    print(f"  ğŸ“Š Active contexts: {len(active_contexts)}")
    
    # Demonstrate memory consolidation
    print("\n7. Memory Consolidation...")
    
    # Perform consolidation
    consolidation_results = await hybrid_memory.consolidator.consolidate_working_to_episodic(
        importance_threshold=0.6
    )
    
    print(f"  ğŸ”„ Consolidated {consolidation_results} items from working to episodic memory")
    
    # Get consolidation metrics
    metrics = hybrid_memory.consolidator.get_consolidation_metrics()
    print(f"  ğŸ“ˆ Total consolidations: {metrics['total_consolidations']}")
    print(f"  ğŸ“ˆ Working to episodic: {metrics['working_to_episodic_count']}")
    print(f"  ğŸ“ˆ Episodic to semantic: {metrics['episodic_to_semantic_count']}")
    
    # Demonstrate integrated search
    print("\n8. Integrated Memory Search...")
    
    # Perform cross-memory search
    # Perform cross-memory search
    query_embedding = np.random.rand(512).astype(np.float32)
    search_results = await hybrid_memory.integrated_search(query_embedding, k=5)
    
    print(f"  ğŸ” Cross-memory search found {len(search_results)} results:")
    memory_types = {}
    for result in search_results:
        memory_type = result['type']
        if memory_type not in memory_types:
            memory_types[memory_type] = 0
        memory_types[memory_type] += 1
    
    for memory_type, count in memory_types.items():
        print(f"    {memory_type}: {count} matches")
    # Display performance metrics
    # Display performance metrics
    print("\n9. Performance Metrics...")
    
    perf_metrics = performance_monitor.get_performance_metrics()
    print(f"  âš¡ Average search latency: {perf_metrics.search_latency_ms:.2f}ms")
    print(f"  âš¡ Average storage latency: {perf_metrics.storage_latency_ms:.2f}ms")
    print(f"  ğŸ’¾ Memory usage: {perf_metrics.memory_usage_mb:.1f}MB")
    print(f"  ğŸ¯ Cache hit rate: {perf_metrics.cache_hit_rate:.2%}")
    print(f"  ğŸ”„ Consolidation rate: {perf_metrics.consolidation_rate:.2f}")
    print(f"  ğŸš€ Throughput: {perf_metrics.throughput_ops_per_sec:.1f} ops/sec")
    
    # Display memory statistics
    print("\n10. Memory Statistics...")
    
    stats = hybrid_memory.get_memory_statistics()
    print(f"  ğŸ“Š Vector memory: {stats['vector_memory_size']} items")
    print(f"  ğŸ“Š Episodic memory: {stats['episodic_memory_size']} events")
    print(f"  ğŸ“Š Semantic memory: {stats['semantic_memory_nodes']} nodes, {stats['semantic_memory_edges']} edges")
    print(f"  ğŸ“Š Working memory: {stats['working_memory_size']} contexts")
    print(f"  ğŸ“Š Total memory items: {stats['total_memory_items']}")
    print("\n" + "=" * 60)
    print("âœ… Hybrid Memory Architecture demonstration completed successfully!")
    print("ğŸ§ª All operations tested using TDD methodology with 83 test cases")
    print("ğŸš€ Ready for integration with SAFLA components")


def demonstrate_optimized_manager():
    """Demonstrate the optimized memory manager."""
    
    print("\nğŸš€ Optimized Memory Manager Demonstration")
    print("=" * 60)
    
    # Create optimized manager
    config = {
        'embedding_dim': 768,
        'similarity_metric': 'cosine',
        'max_capacity': 5000,
        'backend': 'auto'  # Auto-select best available backend
    }
    
    optimized_manager = create_optimized_memory_manager(config)
    
    print(f"âœ… Created optimized manager with {optimized_manager.embedding_dim}D vectors")
    print(f"âœ… Backend: {'External' if optimized_manager._use_backend else 'Default'}")
    print(f"âœ… Capacity: {optimized_manager.max_capacity}")
    
    # Store and search vectors
    embeddings = [np.random.rand(768).astype(np.float32) for _ in range(10)]
    metadata_list = [{"index": i, "category": f"cat_{i % 3}"} for i in range(10)]
    
    # Batch store
    item_ids = optimized_manager.batch_store(embeddings, metadata_list)
    print(f"ğŸ“¦ Batch stored {len(item_ids)} vectors")
    
    # Search
    query = embeddings[0]
    results = optimized_manager.similarity_search(query, k=3)
    print(f"ğŸ” Found {len(results)} similar vectors")
    
    print("âœ… Optimized manager demonstration completed!")


if __name__ == "__main__":
    print("ğŸ§  SAFLA Hybrid Memory Architecture - TDD Implementation Demo")
    print("This demonstration showcases the complete memory system built with TDD")
    print()
    
    # Run the main demonstration
    asyncio.run(demonstrate_hybrid_memory())
    
    # Run optimized manager demonstration
    demonstrate_optimized_manager()
    
    print("\nğŸ‰ All demonstrations completed successfully!")
    print("ğŸ“š See docs/hybrid_memory_architecture_summary.md for detailed documentation")