/**
 * MaTTS: Memory-aware Test-Time Scaling
 * Algorithm 5 from ReasoningBank paper
 *
 * Two modes:
 * - Parallel: k independent rollouts with self-contrast aggregation
 * - Sequential: r iterative refinements with check-and-correct
 */
import { readFileSync } from 'fs';
import { join } from 'path';
import { ulid } from 'ulid';
import { loadConfig } from '../utils/config.js';
import { retrieveMemories } from './retrieve.js';
import { judgeTrajectory } from './judge.js';
import { distillMemories } from './distill.js';
import * as db from '../db/queries.js';
/**
 * Run MaTTS in parallel mode
 * Execute k independent rollouts and aggregate via self-contrast
 */
export async function mattsParallel(taskFn, query, options = {}) {
    const config = loadConfig();
    const k = options.k || config.matts.parallel_k;
    const runId = ulid();
    const startTime = Date.now();
    console.log(`[INFO] Starting MaTTS parallel mode with k=${k}`);
    // Store MaTTS run
    db.storeMattsRun({
        run_id: runId,
        task_id: options.taskId || 'matts-' + runId,
        mode: 'parallel',
        k,
        status: 'running',
        summary: undefined
    });
    const trajectories = [];
    // Execute k independent rollouts
    for (let i = 0; i < k; i++) {
        console.log(`[INFO] MaTTS parallel rollout ${i + 1}/${k}`);
        try {
            const trajectory = await taskFn();
            const verdict = await judgeTrajectory(trajectory, query);
            trajectories.push({
                id: ulid(),
                verdict,
                trajectory
            });
            // Store trajectory
            db.storeTrajectory({
                task_id: options.taskId || 'matts-' + runId,
                agent_id: options.agentId || 'matts-agent',
                query,
                trajectory_json: JSON.stringify(trajectory),
                started_at: new Date().toISOString(),
                ended_at: new Date().toISOString(),
                judge_label: verdict.label,
                judge_conf: verdict.confidence,
                judge_reasons: JSON.stringify(verdict.reasons),
                matts_run_id: runId
            });
        }
        catch (error) {
            console.error(`[ERROR] MaTTS rollout ${i + 1} failed:`, error);
        }
    }
    // Aggregate memories via self-contrast
    const aggregatedMemories = await aggregateMemories(trajectories, query, options);
    const successRate = trajectories.filter(t => t.verdict.label === 'Success').length / trajectories.length;
    const duration = Date.now() - startTime;
    console.log(`[INFO] MaTTS parallel complete: ${trajectories.length} trajectories, ${successRate * 100}% success in ${duration}ms`);
    db.logMetric('rb.matts.parallel.duration_ms', duration);
    db.logMetric('rb.matts.parallel.success_rate', successRate);
    db.logMetric('rb.matts.parallel.memories', aggregatedMemories.length);
    return {
        runId,
        mode: 'parallel',
        k,
        trajectories,
        aggregatedMemories,
        successRate,
        duration
    };
}
/**
 * Run MaTTS in sequential mode
 * Iterative refinement with check-and-correct
 */
export async function mattsSequential(taskFn, query, options = {}) {
    const config = loadConfig();
    const r = options.r || config.matts.sequential_r || config.matts.sequential_k;
    const runId = ulid();
    const startTime = Date.now();
    console.log(`[INFO] Starting MaTTS sequential mode with r=${r}`);
    db.storeMattsRun({
        run_id: runId,
        task_id: options.taskId || 'matts-seq-' + runId,
        mode: 'sequential',
        k: r,
        status: 'running',
        summary: undefined
    });
    const trajectories = [];
    let previousMemories = [];
    // Iterative refinement
    for (let i = 0; i < r; i++) {
        console.log(`[INFO] MaTTS sequential iteration ${i + 1}/${r}`);
        try {
            // Retrieve relevant memories (including from previous iterations)
            const memories = await retrieveMemories(query, {
                domain: options.domain
            });
            // Execute with memories
            const trajectory = await taskFn([...memories, ...previousMemories]);
            const verdict = await judgeTrajectory(trajectory, query);
            trajectories.push({
                id: ulid(),
                verdict,
                trajectory
            });
            // If success and stop_on_success is true, break early
            if (verdict.label === 'Success' && (config.matts.sequential_stop_on_success ?? true)) {
                console.log(`[INFO] Success achieved at iteration ${i + 1}, stopping early`);
                break;
            }
            // Distill memories from this iteration
            const newMemories = await distillMemories(trajectory, verdict, query, options);
            previousMemories = [...previousMemories, ...newMemories];
            // Store trajectory
            db.storeTrajectory({
                task_id: options.taskId || 'matts-seq-' + runId,
                agent_id: options.agentId || 'matts-agent',
                query,
                trajectory_json: JSON.stringify(trajectory),
                started_at: new Date().toISOString(),
                ended_at: new Date().toISOString(),
                judge_label: verdict.label,
                judge_conf: verdict.confidence,
                judge_reasons: JSON.stringify(verdict.reasons),
                matts_run_id: runId
            });
        }
        catch (error) {
            console.error(`[ERROR] MaTTS iteration ${i + 1} failed:`, error);
        }
    }
    const successRate = trajectories.filter(t => t.verdict.label === 'Success').length / trajectories.length;
    const duration = Date.now() - startTime;
    console.log(`[INFO] MaTTS sequential complete: ${trajectories.length} iterations, ${successRate * 100}% success in ${duration}ms`);
    db.logMetric('rb.matts.sequential.duration_ms', duration);
    db.logMetric('rb.matts.sequential.success_rate', successRate);
    return {
        runId,
        mode: 'sequential',
        k: r,
        trajectories,
        aggregatedMemories: previousMemories,
        successRate,
        duration
    };
}
/**
 * Aggregate memories from multiple trajectories using self-contrast
 */
async function aggregateMemories(trajectories, query, options) {
    console.log('[INFO] Aggregating memories via self-contrast');
    // Load aggregation prompt
    const promptPath = join(process.cwd(), 'src', 'reasoningbank', 'prompts', 'matts-aggregate.json');
    const promptTemplate = JSON.parse(readFileSync(promptPath, 'utf-8'));
    // Format trajectories for comparison
    const trajectoryTexts = trajectories.map((t, i) => ({
        id: t.id,
        label: t.verdict.label,
        confidence: t.verdict.confidence,
        steps: JSON.stringify(t.trajectory.steps || [], null, 2)
    }));
    const apiKey = process.env.ANTHROPIC_API_KEY;
    if (!apiKey) {
        console.warn('[WARN] No API key, skipping aggregation');
        return [];
    }
    try {
        const prompt = promptTemplate.template
            .replace('{{k}}', String(trajectories.length))
            .replace('{{task_query}}', query)
            .replace('{{trajectories}}', JSON.stringify(trajectoryTexts, null, 2));
        const response = await fetch('https://api.anthropic.com/v1/messages', {
            method: 'POST',
            headers: {
                'x-api-key': apiKey,
                'anthropic-version': '2023-06-01',
                'content-type': 'application/json'
            },
            body: JSON.stringify({
                model: promptTemplate.model,
                max_tokens: promptTemplate.max_tokens,
                temperature: promptTemplate.temperature,
                system: promptTemplate.system,
                messages: [{ role: 'user', content: prompt }]
            })
        });
        if (!response.ok) {
            throw new Error(`Anthropic API error: ${response.status}`);
        }
        const result = await response.json();
        const content = result.content[0].text;
        // Parse and store aggregated memories
        const jsonMatch = content.match(/\{[\s\S]*\}/);
        if (jsonMatch) {
            const parsed = JSON.parse(jsonMatch[0]);
            const memories = parsed.memories || [];
            // Store with boosted confidence
            const memoryIds = [];
            for (const mem of memories) {
                const verdict = { label: 'Success', confidence: 0.9, reasons: [] };
                const ids = await distillMemories({ steps: [] }, verdict, query, options);
                memoryIds.push(...ids);
            }
            return memoryIds;
        }
    }
    catch (error) {
        console.error('[ERROR] Memory aggregation failed:', error);
    }
    return [];
}
